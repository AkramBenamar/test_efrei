# README
## References
1. MUELLER, Jonas et THYAGARAJAN, Aditya. Siamese recurrent architectures for learning sentence similarity. In : Proceedings of the AAAI conference on artificial intelligence. 2016.

## 1. Introduction
Dans cet exercice, un r√©seau siamois dans une t√¢che de "text-similarity" sur la dataset Quora est explor√©.L'objectif est de trouver si deux question pr√©sente une duplication ou pas. L'architecture de base propos√©e est un siamois √† base de LSTM et la distance Manhatten inspir√© de l'√©tude men√©e par [1]. Dans cette √©tude, le mod√®le siamois de base est entrain√© sur la tache de similarit√© entre des pairs de questions du dataset Quora. Ensuite, l'impact de l'ajout du m√©chanisme d'attention (avant et apr√®s la couche LSTM) est √©tudi√© sur les performances du r√©seau √† trouver des similarit√© des questions. En fin, les couches d'embedding sont remplac√© par des embedding du mod√®le Bert, et une √©tude sur l'impact de l'ajout de cet LLM sur les performances est men√©e.

## 2. Donn√©es (Quora Dataset)
Le dataset Quora Question Pairs est une collection de donn√©es provenant de la plateforme de questions-r√©ponses Quora. Ce dataset est couramment utilis√© pour les t√¢ches de classification de similarit√© de texte et est particuli√®rement int√©ressant pour les mod√®les de r√©seaux siamois (siamese networks).
Colonnes Principales:
- id: Identifiant unique de la paire de questions.
- qid1: Identifiant de la premi√®re question dans la paire.
- qid2: Identifiant de la seconde question dans la paire.
- question1: Texte de la premi√®re question.
- question2: Texte de la seconde question.
- is_duplicate: √âtiquette binaire indiquant si les deux questions sont des duplicatas (1) ou non (0).

Ce dataset est ad√©quoit pour explorer des r√©saux siamois, il est constitu√© de pairs de questions. Le nombre important de paires (400000) favorise l'exploration des m√©canisme d'attention.

Lien du dataset : https://www.kaggle.com/competitions/quora-question-pairs/data




## 3. Siamese LSTM
 
Le r√©seau siamois de base est constitu√© de LSTM (Long Short-Term Memory) pour √©valuer la similarit√© s√©mantique entre phrases. Ce mod√®le exploite des vecteurs d'embeddings de mots enrichis d'informations synonymiques pour capturer le sens profond des phrases. En calculant une m√©trique de Manhattan, le mod√®le oblige les repr√©sentations des phrases √† former un espace  structur√©, donnant des relations s√©mantiques complexes. 

### Architecture du Siamese LSTM

<p align="center">
  <img src="images/siamese_lstm.png" alt="Siamese LSTM Architecture" width="500">
</p>
<p align="center"><em>Figure 1: Architecture du Siamese LSTM</em></p>

Ce mod√®le atteint 81% d'accuracy sur le test set.

## 4. Attention + Siamese LSTM
Un mechanisme de self attention est ajout√© apr√®s(ou avant) la couche LSTM. Les courbes suivantes montre une comparaison entre les performances en accuracy du mo√®le avec couche d'attention (avant et apr√®s LSTM) et sans attention. Le mod√®le avec attention apr√®s couche LSTM atteint 82% d'accuracy en test set.
<p align="center">
  <img src="images/history-beforeattenvslstm-graph.png" alt="Siamese LSTM Architecture" width="500">
</p>
<p align="center"><em>Figure 2: Accuracy pour les mod√®les avec attention avant LSTM et sans attention</em></p>

<p align="center">
  <img src="images/history-attenvslstm-graph.png" alt="Siamese LSTM Architecture" width="500">
</p>
<p align="center"><em>Figure 3: Accuracy pour les mod√®les avec attention avant LSTM et sans attention</em></p>


La couche d'attention plac√©e apr√®s la couche LSTM, augmente les performances en accuracy d'entrainement de mani√®re significative. Le mod√®le apprend plus vite les similarit√©s entre pair. L'accuracy de validation est un meilleur d'un degr√©e moins significatif que dans l'entrainement. 
Pour expliquer le r√©sultat obtenu, il est constat√© que la LSTM a d√©j√† captur√© l'information de toute la s√©quence, y compris les d√©pendances √† long terme. L'attention peut donc se baser sur des repr√©sentations plus riches pour choisir les parties importantes.
La couche d'attention plac√©e avant la couche LSTM n'am√©liore pas les performances du mod√®le, la LSTM n'a pas encore vu la s√©quence compl√®te, donc l'attention est bas√©e uniquement sur les informations locales, ce qui provoque une perte du contexte globale.

Les poids d'attention peuvent √™tre visualis√© dans les figures suivantes. La valeur √† la position (ùëñ,ùëó) dans la matrice d'attention repr√©sente l'importance que la position ùëñ de la s√©quence accorde √† la position ùëó de la s√©quence. 
<p align="center">
  <img src="images/hml.png" alt="Siamese LSTM Architecture" width="500">
</p>
<p align="center"><em>Figure 4: Poids d'attention d'une sequence de test (pair gauche)</em></p>

<p align="center">
  <img src="images/hmr.png" alt="Siamese LSTM Architecture" width="500">
</p>
<p align="center"><em>Figure 4: Poids d'attention d'une sequence de test (pair droite)</em></p>

Cela peut indiquer que les √©l√©ments vers la fin de la s√©quence contiennent des informations cruciales pour le mod√®le, et ces √©l√©ments sont importants pour les positions plus t√¥t dans la s√©quence. Ceci peut √™tre expliqu√© par la nature des donn√©es trait√© (questions), la fin de la phrase contient des √©l√©ments importants pour la compr√©hension s√©mantique.

## 5. Bert
Dans cette partie, la partie embeddings est remplac√© par un BERT pr√©-entrain√©. Pour des raisons de ressources de calcul, cette solution est pr√©sente sous forme d'un notebook.
Les embeddings g√©n√©r√©s par BERT sont de dimension 768 . Cette dimension est beaucoup plus grande que celle des embeddings dans les sc√©narios pr√©c√©dents. Bien que cela peut capturer plus d'informations, il augmente aussi le nombre de param√®tres dans les couches suivantes, ce qui peut ralentir l'entra√Ænement.
Pour cela, un echantillon du dataset est pris pour entrainer le mod√®le. Dans cette √©tude, 6 √©poques ont √©t√© effectu√©, mais les performances en accuracy ne sont pas optimales.

<p align="center">
  <img src="images/BertPerf.png" alt="" width="500">
</p>
<p align="center"><em>Figure 5: accuracy d'entrainement et de validation de Bert-siamese</em></p>

En conclusion, malgr√© la richesse du mod√®le Bert, il peut ne pas r√©ussir dans certaines t√¢ches sp√©cifiques. Le manque de ressources est aussi un point p√©nalisant.

## Utilisation

Pour utiliser ce projet, suivez les √©tapes ci-dessous :
1. Clonez le d√©p√¥t : `git clone https://github.com/AkramBenamar/test_efrei.git`
2. Entrainer et √©valuer le mod√®le siamois lstm : `python main.py --model siamese_lstm --data_directory path_to_data --max_seq_length 20 --sample_size 10000 --n_epoch 50 --batch_size 2048`
3. avec attention : `python main.py --model attention_siamese_lstm --data_directory pat_to_data --max_seq_length 20 --sample_size 10000 --n_epoch 50 --batch_size 2048`
4. avec Bert ; `voir bert_siamese.ipynb`

